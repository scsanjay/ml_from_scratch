{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01. Bow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+XL2+n1BoFJ/6bgYNKkCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scsanjay/ml_from_scratch/blob/main/01.%20Bag%20of%20Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhdf3zcs-lCQ"
      },
      "source": [
        "BoW (Bag of Words) is one of the simplest technique to convert document into vectors. These documents can be text message, review, email,etc. We can not perform any ml operations on any data unless it's in numeric form.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The BoW are of length equal to number of unique words in the corpus (corpus is collection of documents). We represent each document with the vector of same length. And each cell in the vector keeps the count of occurence of the word in that document. If it is Boolean BoW, we use 1 if the word is present in the document otherwise 0. Since the vectors are very sparse we will use compressed sparse row matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj_4xLH8-Pz3"
      },
      "source": [
        "from scipy.sparse import csr_matrix,lil_matrix\n",
        "import numpy as np\n",
        "\n",
        "class Bow:\n",
        "  \"\"\"\n",
        "  Converts a corpus into vector representation\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  binary : bool, default=False\n",
        "      If True it will return Boolean BoW.\n",
        "\n",
        "  Attributes\n",
        "  ----------\n",
        "  vocabulary_ : dict\n",
        "      Dictionary with key as the features and the values as the\n",
        "  \n",
        "  Methods\n",
        "  -------\n",
        "  fit(corpus) : return self;\n",
        "  transform(corpus) : return scipy.sparse.csr_matrix;\n",
        "  fit_transform(corpus) : return scipy.sparse.csr_matrix;\n",
        "  get_feature_names(corpus) : return list;\n",
        "\n",
        "  Note\n",
        "  -----\n",
        "  It assumes the data is already preprocessed.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, binary=False):\n",
        "    self.binary = binary\n",
        "  \n",
        "  def fit(self, corpus):\n",
        "    \"\"\"\n",
        "    It will learn the vocabulary from the given corpus.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    corpus : iterable\n",
        "        A list of documents.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    self\n",
        "    \"\"\"\n",
        "    if len(corpus)==0:\n",
        "      raise ValueError('Empty corpus provided.')\n",
        "    self.vocabulary = set()\n",
        "    for document in corpus:\n",
        "      document = set(document.split())\n",
        "      self.vocabulary = self.vocabulary.union(document)\n",
        "    self.vocabulary = sorted(list(self.vocabulary))\n",
        "    self.no_of_features = len(self.vocabulary)\n",
        "    self.vocabulary_ = {j:i for i,j in enumerate(self.vocabulary)}\n",
        "\n",
        "  def transform(self, corpus):\n",
        "    \"\"\"\n",
        "    It will transform the corpus into sparsed matrix and return it.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    corpus : iterable\n",
        "        A list of documents.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    scipy.sparse.csr_matrix\n",
        "    \"\"\"\n",
        "    if not hasattr(self, 'vocabulary_'):\n",
        "      raise NotImplementedError('fit method not called yet.')\n",
        "    self.no_of_documents = len(corpus)\n",
        "    corpus_array = lil_matrix((self.no_of_documents, self.no_of_features), dtype=np.int8)\n",
        "    for i,document in enumerate(corpus):\n",
        "      document = document.split()\n",
        "      for feature in set(document):\n",
        "        feature_index = self.vocabulary_.get(feature)\n",
        "        if feature_index != None:\n",
        "          count = document.count(feature)\n",
        "          if self.binary and count:\n",
        "            count = 1\n",
        "          corpus_array[i,feature_index] = count\n",
        "    corpus_array = corpus_array.tocsr()\n",
        "    corpus_array.sort_indices()\n",
        "    return corpus_array\n",
        "\n",
        "  def fit_transform(self, corpus):\n",
        "    \"\"\"\n",
        "    It will learn the vocabulary and transform the corpus into sparsed matrix and return it.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    corpus : iterable\n",
        "        A list of documents.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    scipy.sparse.csr_matrix\n",
        "    \"\"\"\n",
        "    self.fit(corpus)\n",
        "    corpus_array = self.transform(corpus)\n",
        "    return corpus_array\n",
        "\n",
        "  def get_feature_names(self):\n",
        "    \"\"\"\n",
        "    It will transform the corpus into sparsed matrix.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    corpus : iterable\n",
        "        A list of documents.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    scipy.sparse.csr_matrix\n",
        "    \"\"\"\n",
        "    if not hasattr(self, 'vocabulary'):\n",
        "      raise NotImplementedError('fit or fit_transform method not called yet.')\n",
        "    return self.vocabulary\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMTyM11lpL6k"
      },
      "source": [
        "##Compare Bow with sklearn's CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNUHXGEESTUy"
      },
      "source": [
        "corpus = [\n",
        "    'this is the first document',\n",
        "    'this document is the second document',\n",
        "    'and this is the third one',\n",
        "    'is this the first document',\n",
        "]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PzD60PshKF7",
        "outputId": "a5ebacef-8f4c-459a-f630-e2a8213cfbc9"
      },
      "source": [
        "model = Bow()\n",
        "model.fit(corpus)\n",
        "X = model.transform(corpus)\n",
        "print(model.get_feature_names())\n",
        "print(model.vocabulary_)\n",
        "print(X.toarray())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "{'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8}\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj8nqVFBpkwS",
        "outputId": "ff0b3857-143a-4bf4-fbf8-a74bad753805"
      },
      "source": [
        "model = Bow()\n",
        "X = model.fit_transform(corpus)\n",
        "print(model.get_feature_names())\n",
        "print(model.vocabulary_)\n",
        "print(X.toarray())"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "{'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8}\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRkYDElgpZn9"
      },
      "source": [
        "We are getting same results while using fit_transform and fit followed by transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq0Sh6JNcCCx",
        "outputId": "8ee59874-ecb0-4b8f-ad4f-c7e14ba1b2a6"
      },
      "source": [
        "model = Bow()\n",
        "X = model.fit_transform(corpus)\n",
        "print(model.get_feature_names())\n",
        "print(model.vocabulary_)\n",
        "print(X.toarray())\n",
        "print('-'*50)\n",
        "model2 = Bow(binary=True)\n",
        "X = model2.fit_transform(corpus)\n",
        "print(X.toarray())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "{'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8}\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n",
            "--------------------------------------------------\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 1 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuCBEDSNF627",
        "outputId": "3c6ffcb5-a585-43b1-a4e7-44c9d62454b9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names())\n",
        "print(vectorizer.vocabulary_)\n",
        "print(X.toarray())\n",
        "print('-'*50)\n",
        "vectorizer2 = CountVectorizer(binary=True)\n",
        "X = vectorizer2.fit_transform(corpus)\n",
        "print(X.toarray())"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n",
            "--------------------------------------------------\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 1 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6pyR9OlpziH"
      },
      "source": [
        "Both results, from our implementation and sklearn's implementation are similar."
      ]
    }
  ]
}