{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01. Bow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMS4ehNZIcraGlE6aQbf6AI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scsanjay/ml_from_scratch/blob/main/01.%20Bag%20of%20Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhdf3zcs-lCQ"
      },
      "source": [
        "BoW (Bag of Words) is one of the simplest technique to convert document into vectors. These documents can be text message, review, email,etc. We can not perform any ml operations on any data unless it's in numeric form.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The BoW are of length equal to number of unique words in the corpus (corpus is collection of documents). We represent each document with the vector of same length. And each cell in the vector keeps the count of occurence of the word in that document. If it is Boolean BoW, we use 1 if the word is present in the document otherwise 0. Since the vectors are very sparse we will use compressed sparse row matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDjvzpQ_tRGd"
      },
      "source": [
        "##Custom Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj_4xLH8-Pz3"
      },
      "source": [
        "from scipy.sparse import csr_matrix,lil_matrix\n",
        "import numpy as np\n",
        "\n",
        "class Bow:\n",
        "  \"\"\"\n",
        "  Converts a corpus into vector representation\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  binary : bool, default=False\n",
        "      If True it will return Boolean BoW.\n",
        "\n",
        "  Attributes\n",
        "  ----------\n",
        "  vocabulary_ : dict\n",
        "      Dictionary with key as the features and the values as the\n",
        " \n",
        "  Note\n",
        "  -----\n",
        "  It assumes the data is already preprocessed.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, binary=False):\n",
        "    self.binary = binary\n",
        "  \n",
        "  def fit(self, corpus):\n",
        "    \"\"\"\n",
        "    It will learn the vocabulary from the given corpus.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    corpus : iterable\n",
        "        A list of documents.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    self\n",
        "    \"\"\"\n",
        "    if len(corpus)==0:\n",
        "      raise ValueError('Empty corpus provided.')\n",
        "    self.vocabulary = set()\n",
        "    for document in corpus:\n",
        "      document = set(document.split())\n",
        "      self.vocabulary = self.vocabulary.union(document)\n",
        "    self.vocabulary = sorted(list(self.vocabulary))\n",
        "    self.no_of_features = len(self.vocabulary)\n",
        "    self.vocabulary_ = {j:i for i,j in enumerate(self.vocabulary)}\n",
        "\n",
        "  def transform(self, corpus):\n",
        "    \"\"\"\n",
        "    It will transform the corpus into sparsed matrix and return it.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    corpus : iterable\n",
        "        A list of documents.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    scipy.sparse.csr_matrix\n",
        "    \"\"\"\n",
        "    if not hasattr(self, 'vocabulary_'):\n",
        "      raise Exception('fit method not called yet.')\n",
        "    self.no_of_documents = len(corpus)\n",
        "    corpus_array = lil_matrix((self.no_of_documents, self.no_of_features), dtype=np.int8)\n",
        "    for i,document in enumerate(corpus):\n",
        "      document = document.split()\n",
        "      for feature in set(document):\n",
        "        feature_index = self.vocabulary_.get(feature)\n",
        "        if feature_index != None:\n",
        "          count = document.count(feature)\n",
        "          if self.binary and count:\n",
        "            count = 1\n",
        "          corpus_array[i,feature_index] = count\n",
        "    corpus_array = corpus_array.tocsr()\n",
        "    corpus_array.sort_indices()\n",
        "    return corpus_array\n",
        "\n",
        "  def fit_transform(self, corpus):\n",
        "    \"\"\"\n",
        "    It will learn the vocabulary and transform the corpus into sparsed matrix and return it.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    corpus : iterable\n",
        "        A list of documents.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    scipy.sparse.csr_matrix\n",
        "    \"\"\"\n",
        "    self.fit(corpus)\n",
        "    corpus_array = self.transform(corpus)\n",
        "    return corpus_array\n",
        "\n",
        "  def get_feature_names(self):\n",
        "    \"\"\"\n",
        "    It will transform the corpus into sparsed matrix.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "    \"\"\"\n",
        "    if not hasattr(self, 'vocabulary'):\n",
        "      raise NotImplementedError('fit or fit_transform method not called yet.')\n",
        "    return self.vocabulary\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMTyM11lpL6k"
      },
      "source": [
        "##Compare Bow with sklearn's CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNUHXGEESTUy"
      },
      "source": [
        "corpus = [\n",
        "    'this is the first document',\n",
        "    'this document is the second document',\n",
        "    'and this is the third one',\n",
        "    'is this the first document',\n",
        "]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PzD60PshKF7",
        "outputId": "a1b70ba9-f09a-4c6b-c3e0-cb84895ab3e1"
      },
      "source": [
        "model = Bow()\n",
        "model.fit(corpus)\n",
        "X = model.transform(corpus)\n",
        "print(model.get_feature_names())\n",
        "print(model.vocabulary_)\n",
        "print(X.toarray())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "{'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8}\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj8nqVFBpkwS",
        "outputId": "09f7aef0-cdca-4128-f594-36d3c98e2987"
      },
      "source": [
        "model = Bow()\n",
        "X = model.fit_transform(corpus)\n",
        "print(model.get_feature_names())\n",
        "print(model.vocabulary_)\n",
        "print(X.toarray())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "{'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8}\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRkYDElgpZn9"
      },
      "source": [
        "We are getting same results while using fit_transform and fit followed by transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq0Sh6JNcCCx",
        "outputId": "4ecf22c3-3d84-439a-98c5-30f952613f69"
      },
      "source": [
        "model = Bow()\n",
        "X = model.fit_transform(corpus)\n",
        "print(model.get_feature_names())\n",
        "print(model.vocabulary_)\n",
        "print(X.toarray())\n",
        "print('-'*50)\n",
        "model2 = Bow(binary=True)\n",
        "X = model2.fit_transform(corpus)\n",
        "print(X.toarray())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "{'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8}\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n",
            "--------------------------------------------------\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 1 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuCBEDSNF627",
        "outputId": "69945b62-4b36-4a15-a88b-9d822f6e3fbf"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names())\n",
        "print(vectorizer.vocabulary_)\n",
        "print(X.toarray())\n",
        "print('-'*50)\n",
        "vectorizer2 = CountVectorizer(binary=True)\n",
        "X = vectorizer2.fit_transform(corpus)\n",
        "print(X.toarray())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n",
            "--------------------------------------------------\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 1 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6pyR9OlpziH"
      },
      "source": [
        "Both results, from our implementation and sklearn's implementation are similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUMad7DdrC7W"
      },
      "source": [
        "##Documentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCcvVP0wrHDg",
        "outputId": "c755bc11-e92d-4bc1-f80e-cf379b4d594d"
      },
      "source": [
        "help(Bow)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class Bow in module __main__:\n",
            "\n",
            "class Bow(builtins.object)\n",
            " |  Bow(binary=False)\n",
            " |  \n",
            " |  Converts a corpus into vector representation\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  binary : bool, default=False\n",
            " |      If True it will return Boolean BoW.\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  vocabulary_ : dict\n",
            " |      Dictionary with key as the features and the values as the\n",
            " |  \n",
            " |  Note\n",
            " |  -----\n",
            " |  It assumes the data is already preprocessed.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, binary=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, corpus)\n",
            " |      It will learn the vocabulary from the given corpus.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      corpus : iterable\n",
            " |          A list of documents.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |  \n",
            " |  fit_transform(self, corpus)\n",
            " |      It will learn the vocabulary and transform the corpus into sparsed matrix and return it.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      corpus : iterable\n",
            " |          A list of documents.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      scipy.sparse.csr_matrix\n",
            " |  \n",
            " |  get_feature_names(self)\n",
            " |      It will transform the corpus into sparsed matrix.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      list\n",
            " |  \n",
            " |  transform(self, corpus)\n",
            " |      It will transform the corpus into sparsed matrix and return it.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      corpus : iterable\n",
            " |          A list of documents.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      scipy.sparse.csr_matrix\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8JnnnOLrIr2",
        "outputId": "0b752438-7d65-4f72-c423-e9c0b23d8737"
      },
      "source": [
        "help(Bow.fit_transform)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function fit_transform in module __main__:\n",
            "\n",
            "fit_transform(self, corpus)\n",
            "    It will learn the vocabulary and transform the corpus into sparsed matrix and return it.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    corpus : iterable\n",
            "        A list of documents.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    scipy.sparse.csr_matrix\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_K5iJflsA8V"
      },
      "source": [
        "##Exceptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "ZcRVsMBRsJCt",
        "outputId": "c0290c0c-c823-436f-8dcc-8f6c108cf402"
      },
      "source": [
        "model = Bow()\n",
        "X = model.fit_transform([])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-e7835af8d875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-248e81feb551>\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mcorpus_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorpus_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-248e81feb551>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \"\"\"\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Empty corpus provided.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Empty corpus provided."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "S-PZ95cFsLbe",
        "outputId": "f6c86a8d-8513-4dd2-af26-b510966f2df9"
      },
      "source": [
        "model = Bow()\n",
        "X = model.transform(corpus)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-8ae690384b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-248e81feb551>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \"\"\"\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocabulary_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit method not called yet.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mcorpus_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: fit method not called yet."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON9kHOrPtIBG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}